name: creationhub-ai-transcribe

services:
  # Faster Whisper Server (OpenAI Compatible API)
  # Docs: https://github.com/fedirz/faster-whisper-server
  ai-transcribe:
    image: fedirz/faster-whisper-server:latest-cuda
    container_name: creationhub-ai-transcribe
    restart: unless-stopped
    labels:
      - com.centurylinklabs.watchtower.scope=apps
    networks:
      - backend
      - egress
    ports:
      - "8000:8000" # Internal API
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - /home/inno/creationhub/orchestration/volumes/ai/whisper:/root/.cache/huggingface
    environment:
      # Use medium for balance of speed/quality (large-v3 for max accuracy)
      - WHISPER_MODEL=medium
      - WHISPER_BEAM_SIZE=3
      - WHISPER_COMPUTE_TYPE=float16
      # OpenAI API compatibility
      - UVICORN_HOST=0.0.0.0
      - UVICORN_PORT=8000

networks:
  backend:
    external: true
    name: creationhub-backend
  egress:
    external: true
    name: creationhub-egress

